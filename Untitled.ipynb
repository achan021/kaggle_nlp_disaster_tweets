{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning pipeline (NLP)\n",
    "1) preprocessing [X]\n",
    "2) feature engineering []\n",
    "3) feature selection []\n",
    "4) vectorization []\n",
    "5) dataset splitting []\n",
    "6) model training | model selection []\n",
    "7) hyper param tuning []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and declarations\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "\n",
    "#This is to enable a fancy user display for .progress_apply()\n",
    "tqdm_notebook.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 7613 rows and 5 columns\n",
      "The number of missing data in id : 0\n",
      "The number of missing data in keyword : 61\n",
      "The number of missing data in location : 2533\n",
      "The number of missing data in text : 0\n",
      "The number of missing data in target : 0\n"
     ]
    }
   ],
   "source": [
    "#use this to check the current working directory to do relative links\n",
    "#print(os.getcwd())\n",
    "\n",
    "#increase the width of the pandas dataframe display\n",
    "pd.set_option('display.width', 2000)\n",
    "\n",
    "#Reading of the CSV file\n",
    "train_csv_link = \"./datasets/train.csv\"\n",
    "test_csv_link = \"./datasets/test.csv\"\n",
    "\n",
    "train_csv = pd.read_csv(train_csv_link)\n",
    "test_csv = pd.read_csv(test_csv_link)\n",
    "\n",
    "#get the column names \n",
    "train_col_index = [index for index in train_csv.columns]\n",
    "test_col_index = [index for index in test_csv.columns]\n",
    "\n",
    "#understand the training dataset\n",
    "print(\"The training dataset has {} rows and {} columns\".format(len(train_csv) , len(train_csv.columns)))\n",
    "for index in train_col_index:\n",
    "    print(\"The number of missing data in {} : {}\".format(index,train_csv[index].isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>[our, deed, reason, earthquak, may, allah, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>[forest, fire, near, La, rong, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>[all, resid, ask, shelter, place, notifi, offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>[13000, peopl, receiv, wildfir, evacu, order, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>[just, got, sent, photo, rubi, alaska, smoke, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \\\n",
       "0       1  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1       1              Forest fire near La Ronge Sask Canada   \n",
       "2       1  All residents asked to shelter in place are be...   \n",
       "3       1  13000 people receive wildfires evacuation orde...   \n",
       "4       1  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                          text_token  \n",
       "0  [our, deed, reason, earthquak, may, allah, for...  \n",
       "1       [forest, fire, near, La, rong, sask, canada]  \n",
       "2  [all, resid, ask, shelter, place, notifi, offi...  \n",
       "3  [13000, peopl, receiv, wildfir, evacu, order, ...  \n",
       "4  [just, got, sent, photo, rubi, alaska, smoke, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning part of the pipeline (preprocessing)\n",
    "#we will clean the text labels\n",
    "\n",
    "#define a function to parse the text into\n",
    "def remove_punctuation(text):\n",
    "    clean_text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return clean_text\n",
    "#tokenize clean_text\n",
    "def tokenize_text (text):\n",
    "    #\\W+ refers to the regex for non charcter words [^a-zA-Z0-9_]\n",
    "    tokens = re.split(\"\\W+\",text)\n",
    "    return tokens\n",
    "#remove stopwords\n",
    "def rm_stopwords(text_list):\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    clean_list = [word for word in text_list if word not in stopwords]\n",
    "    return clean_list\n",
    "#stemming of text_token\n",
    "def stem_text(text_list):\n",
    "    #we use porter stemmer for now\n",
    "    ps = nltk.PorterStemmer()\n",
    "    stem_list = [ps.stem(word) for word in text_list]\n",
    "    return stem_list\n",
    "\n",
    "#produce clean text without punctuations\n",
    "train_csv[\"clean_text\"] = train_csv[\"text\"].apply(lambda x : remove_punctuation(x))\n",
    "train_csv[\"text_token\"] = train_csv[\"clean_text\"].apply(lambda x : tokenize_text(x))\n",
    "train_csv[\"text_token\"] = train_csv[\"text_token\"].apply(lambda x : rm_stopwords(x))\n",
    "train_csv[\"text_token\"] = train_csv[\"text_token\"].apply(lambda x : stem_text(x))\n",
    "\n",
    "\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering ideas :\n",
    "1) number of punctuations [X]\n",
    "2) number of capital letters [X]\n",
    "3) presence of links [X]\n",
    "4) number of words\n",
    "5) number of hashtags\n",
    "6) number of weather words / natural disaster / life threat words\n",
    "7) number of country words\n",
    "8) number of mispelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>link_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>this is ridiculous....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>London is cool ;)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Love skiing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What a wonderful day!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LOOOOOOL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>No way...I can't eat that shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Was in NYC last week!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Love my girlfriend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cooool :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Do you like pasta?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>Pic of 16yr old PKK suicide bomber who detonat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>These boxes are ready to explode! Exploding Ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>Calgary Police Flood Road Closures in Calgary....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>#Sismo DETECTADO #JapÌ_n 15:41:07 Seismic inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>Sirens everywhere!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>BREAKING: #ISIS claims responsibility for mosq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7589</th>\n",
       "      <td>Omg earthquake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>SEVERE WEATHER BULLETIN No. 5 FOR: TYPHOON ÛÏ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>Heat wave warning aa? Ayyo dei. Just when I pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>An IS group suicide bomber detonated an explos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>I just heard a really loud bang and everyone i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>A gas thing just exploded and I heard screams ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>NWS: Flash Flood Warning Continued for Shelby ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>RT @LivingSafely: #NWS issues Severe #Thunders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>#??? #?? #??? #??? MH370: Aircraft debris foun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>Father-of-three Lost Control of Car After Over...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>1.3 #Earthquake in 9Km Ssw Of Anza California ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>Evacuation order lifted for town of Roosevelt:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>#breaking #LA Refugio oil spill may have been ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>a siren just went off and it wasn't the Forney...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>Officials say a quarantine is in place at an A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>on the flip side I'm at Walmart and there is a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>#stormchase Violent Record Breaking EF-5 El Re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  link_count\n",
       "0     Our Deeds are the Reason of this #earthquake M...           0\n",
       "1                Forest fire near La Ronge Sask. Canada           0\n",
       "2     All residents asked to 'shelter in place' are ...           0\n",
       "3     13,000 people receive #wildfires evacuation or...           0\n",
       "4     Just got sent this photo from Ruby #Alaska as ...           0\n",
       "5     #RockyFire Update => California Hwy. 20 closed...           0\n",
       "6     #flood #disaster Heavy rain causes flash flood...           0\n",
       "7     I'm on top of the hill and I can see a fire in...           0\n",
       "8     There's an emergency evacuation happening now ...           0\n",
       "9     I'm afraid that the tornado is coming to our a...           0\n",
       "10          Three people died from the heat wave so far           0\n",
       "11    Haha South Tampa is getting flooded hah- WAIT ...           0\n",
       "12    #raining #flooding #Florida #TampaBay #Tampa 1...           0\n",
       "13              #Flood in Bago Myanmar #We arrived Bago           0\n",
       "14    Damage to school bus on 80 in multi car crash ...           0\n",
       "15                                       What's up man?           0\n",
       "16                                        I love fruits           0\n",
       "17                                     Summer is lovely           0\n",
       "18                                    My car is so fast           0\n",
       "19                         What a goooooooaaaaaal!!!!!!           0\n",
       "20                               this is ridiculous....           0\n",
       "21                                    London is cool ;)           0\n",
       "22                                          Love skiing           0\n",
       "23                                What a wonderful day!           0\n",
       "24                                             LOOOOOOL           0\n",
       "25                       No way...I can't eat that shit           0\n",
       "26                                Was in NYC last week!           0\n",
       "27                                   Love my girlfriend           0\n",
       "28                                            Cooool :)           0\n",
       "29                                   Do you like pasta?           0\n",
       "...                                                 ...         ...\n",
       "7583  Pic of 16yr old PKK suicide bomber who detonat...           1\n",
       "7584  These boxes are ready to explode! Exploding Ki...           1\n",
       "7585  Calgary Police Flood Road Closures in Calgary....           1\n",
       "7586  #Sismo DETECTADO #JapÌ_n 15:41:07 Seismic inte...           1\n",
       "7587                                 Sirens everywhere!           0\n",
       "7588  BREAKING: #ISIS claims responsibility for mosq...           1\n",
       "7589                                     Omg earthquake           0\n",
       "7590  SEVERE WEATHER BULLETIN No. 5 FOR: TYPHOON ÛÏ...           1\n",
       "7591  Heat wave warning aa? Ayyo dei. Just when I pl...           0\n",
       "7592  An IS group suicide bomber detonated an explos...           0\n",
       "7593  I just heard a really loud bang and everyone i...           0\n",
       "7594  A gas thing just exploded and I heard screams ...           0\n",
       "7595  NWS: Flash Flood Warning Continued for Shelby ...           1\n",
       "7596  RT @LivingSafely: #NWS issues Severe #Thunders...           1\n",
       "7597  #??? #?? #??? #??? MH370: Aircraft debris foun...           1\n",
       "7598  Father-of-three Lost Control of Car After Over...           1\n",
       "7599  1.3 #Earthquake in 9Km Ssw Of Anza California ...           1\n",
       "7600  Evacuation order lifted for town of Roosevelt:...           1\n",
       "7601  #breaking #LA Refugio oil spill may have been ...           1\n",
       "7602  a siren just went off and it wasn't the Forney...           0\n",
       "7603  Officials say a quarantine is in place at an A...           1\n",
       "7604  #WorldNews Fallen powerlines on G:link tram: U...           1\n",
       "7605  on the flip side I'm at Walmart and there is a...           0\n",
       "7606  Suicide bomber kills 15 in Saudi security site...           1\n",
       "7607  #stormchase Violent Record Breaking EF-5 El Re...           1\n",
       "7608  Two giant cranes holding a bridge collapse int...           1\n",
       "7609  @aria_ahrary @TheTawniest The out of control w...           0\n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...           1\n",
       "7611  Police investigating after an e-bike collided ...           0\n",
       "7612  The Latest: More Homes Razed by Northern Calif...           1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of punctuations\n",
    "def count_punc (text):\n",
    "    count = 0\n",
    "    for char in text:\n",
    "        if char in string.punctuation:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#count the number of capital letters\n",
    "def count_cap (text):\n",
    "    count = 0\n",
    "    for char in text:\n",
    "        if char.isupper() is True:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#boolean of links\n",
    "def link_bool(text):\n",
    "    if re.search(\"http[s]?\\:\\/\\/\",text) not in [None,\"None\"]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "train_csv[\"punc_count\"] = train_csv[\"text\"].apply(lambda x : count_punc(x))\n",
    "train_csv[\"capital_count\"] = train_csv[\"text\"].apply(lambda x : count_cap(x))\n",
    "train_csv[\"link_count\"] = train_csv[\"text\"].apply(lambda x : link_bool(x))\n",
    "train_csv[[\"text\",\"link_count\"]]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
